{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: Work done so far: change all data types, drop some corrupted rows with at start_time and end_time\n",
    "Delete all rows with null value.\n",
    "Calculating idle time (station-level and trip-level)\n",
    "\n",
    "Import weather data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all relevant libraries\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "\n",
    "# also import these \"new\" libraries\n",
    "# Note: you may have to download an add them to your environment (using e.g. 'conda install -c conda-forge folium')\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from datetime import datetime  # for working with times objects\n",
    "from datetime import timedelta  # for working with times objects\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/2xng7w014d1f2mbbxqsxbwg40000gn/T/ipykernel_7668/1972288972.py:2: DtypeWarning: Columns (3,4,5,6,7,8,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"baywheels_2019\", encoding=\"ISO-8859-1\", index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_lat</th>\n",
       "      <th>start_station_lon</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_lat</th>\n",
       "      <th>end_station_lon</th>\n",
       "      <th>bike_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-28 09:46:47</td>\n",
       "      <td>2019-10-28 09:51:05</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.780526</td>\n",
       "      <td>-122.390288</td>\n",
       "      <td>453.0</td>\n",
       "      <td>37.777934</td>\n",
       "      <td>-122.396973</td>\n",
       "      <td>12424.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-10 19:31:02</td>\n",
       "      <td>2019-08-10 19:35:05</td>\n",
       "      <td>285.0</td>\n",
       "      <td>37.783521</td>\n",
       "      <td>-122.431158</td>\n",
       "      <td>74.0</td>\n",
       "      <td>37.776435</td>\n",
       "      <td>-122.426244</td>\n",
       "      <td>1718.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-27 13:18:58</td>\n",
       "      <td>2019-05-27 13:46:37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.795393</td>\n",
       "      <td>-122.40477</td>\n",
       "      <td>399.0</td>\n",
       "      <td>37.802636</td>\n",
       "      <td>-122.436289</td>\n",
       "      <td>608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-24 22:47:58</td>\n",
       "      <td>2019-07-24 22:52:48</td>\n",
       "      <td>106.0</td>\n",
       "      <td>37.763242</td>\n",
       "      <td>-122.430675</td>\n",
       "      <td>72.0</td>\n",
       "      <td>37.772406</td>\n",
       "      <td>-122.43565</td>\n",
       "      <td>551642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-28 17:26:22</td>\n",
       "      <td>2019-04-28 17:31:54</td>\n",
       "      <td>80.0</td>\n",
       "      <td>37.775235</td>\n",
       "      <td>-122.397437</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.780526</td>\n",
       "      <td>-122.390288</td>\n",
       "      <td>1103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-04-17 19:39:05</td>\n",
       "      <td>2019-04-17 19:49:26</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.7671</td>\n",
       "      <td>-122.410662</td>\n",
       "      <td>74.0</td>\n",
       "      <td>37.776435</td>\n",
       "      <td>-122.426244</td>\n",
       "      <td>1473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-02-26 08:11:01</td>\n",
       "      <td>2019-02-26 08:22:58</td>\n",
       "      <td>67.0</td>\n",
       "      <td>37.776639</td>\n",
       "      <td>-122.395526</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.799953</td>\n",
       "      <td>-122.398525</td>\n",
       "      <td>4984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-02-02 09:23:15</td>\n",
       "      <td>2019-02-02 09:34:20</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.781074</td>\n",
       "      <td>-122.411738</td>\n",
       "      <td>55.0</td>\n",
       "      <td>37.777053</td>\n",
       "      <td>-122.429558</td>\n",
       "      <td>2666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-05-07 12:08:01</td>\n",
       "      <td>2019-05-07 12:12:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>37.798572</td>\n",
       "      <td>-122.400869</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.80477</td>\n",
       "      <td>-122.403234</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-09-04 21:58:19</td>\n",
       "      <td>2019-09-04 22:09:07</td>\n",
       "      <td>86.0</td>\n",
       "      <td>37.769305</td>\n",
       "      <td>-122.426826</td>\n",
       "      <td>39.0</td>\n",
       "      <td>37.778999</td>\n",
       "      <td>-122.436861</td>\n",
       "      <td>9717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-06-12 18:04:25</td>\n",
       "      <td>2019-06-12 18:15:57</td>\n",
       "      <td>241.0</td>\n",
       "      <td>37.852477</td>\n",
       "      <td>-122.270213</td>\n",
       "      <td>271.0</td>\n",
       "      <td>37.855783</td>\n",
       "      <td>-122.283127</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-08-31 13:12:58</td>\n",
       "      <td>2019-08-31 13:34:22</td>\n",
       "      <td>304.0</td>\n",
       "      <td>37.348759</td>\n",
       "      <td>-121.894798</td>\n",
       "      <td>282.0</td>\n",
       "      <td>37.332426</td>\n",
       "      <td>-121.890349</td>\n",
       "      <td>3412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-10-17 08:56:41</td>\n",
       "      <td>2019-10-17 09:02:35</td>\n",
       "      <td>61.0</td>\n",
       "      <td>37.776513</td>\n",
       "      <td>-122.411306</td>\n",
       "      <td>90.0</td>\n",
       "      <td>37.771058</td>\n",
       "      <td>-122.402717</td>\n",
       "      <td>12353.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-02-12 07:11:41</td>\n",
       "      <td>2019-02-12 07:15:22</td>\n",
       "      <td>223.0</td>\n",
       "      <td>37.764765</td>\n",
       "      <td>-122.420091</td>\n",
       "      <td>100.0</td>\n",
       "      <td>37.7671</td>\n",
       "      <td>-122.410662</td>\n",
       "      <td>5185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-03-13 11:36:57</td>\n",
       "      <td>2019-03-13 11:45:29</td>\n",
       "      <td>252.0</td>\n",
       "      <td>37.865847</td>\n",
       "      <td>-122.267443</td>\n",
       "      <td>241.0</td>\n",
       "      <td>37.852477</td>\n",
       "      <td>-122.270213</td>\n",
       "      <td>5172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-02-01 11:38:20</td>\n",
       "      <td>2019-02-01 11:53:14</td>\n",
       "      <td>139.0</td>\n",
       "      <td>37.751017</td>\n",
       "      <td>-122.411901</td>\n",
       "      <td>104.0</td>\n",
       "      <td>37.767045</td>\n",
       "      <td>-122.390833</td>\n",
       "      <td>4813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-07-10 17:16:46</td>\n",
       "      <td>2019-07-10 17:23:22</td>\n",
       "      <td>79.0</td>\n",
       "      <td>37.773492</td>\n",
       "      <td>-122.403672</td>\n",
       "      <td>44.0</td>\n",
       "      <td>37.781074</td>\n",
       "      <td>-122.411738</td>\n",
       "      <td>1312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-28 13:49:45</td>\n",
       "      <td>2019-07-28 14:17:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.806791</td>\n",
       "      <td>-122.419491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.798469</td>\n",
       "      <td>-122.401155</td>\n",
       "      <td>928582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-12-23 09:06:10</td>\n",
       "      <td>2019-12-23 09:10:45</td>\n",
       "      <td>323.0</td>\n",
       "      <td>37.798014</td>\n",
       "      <td>-122.40595</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.795001</td>\n",
       "      <td>-122.39997</td>\n",
       "      <td>12895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-01-10 09:55:28</td>\n",
       "      <td>2019-01-10 09:59:27</td>\n",
       "      <td>223.0</td>\n",
       "      <td>37.764765</td>\n",
       "      <td>-122.420091</td>\n",
       "      <td>112.0</td>\n",
       "      <td>37.763847</td>\n",
       "      <td>-122.413004</td>\n",
       "      <td>845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             start_time             end_time start_station_id  \\\n",
       "0   2019-10-28 09:46:47  2019-10-28 09:51:05             50.0   \n",
       "1   2019-08-10 19:31:02  2019-08-10 19:35:05            285.0   \n",
       "2   2019-05-27 13:18:58  2019-05-27 13:46:37             10.0   \n",
       "3   2019-07-24 22:47:58  2019-07-24 22:52:48            106.0   \n",
       "4   2019-04-28 17:26:22  2019-04-28 17:31:54             80.0   \n",
       "5   2019-04-17 19:39:05  2019-04-17 19:49:26            100.0   \n",
       "6   2019-02-26 08:11:01  2019-02-26 08:22:58             67.0   \n",
       "7   2019-02-02 09:23:15  2019-02-02 09:34:20             44.0   \n",
       "8   2019-05-07 12:08:01  2019-05-07 12:12:00              9.0   \n",
       "9   2019-09-04 21:58:19  2019-09-04 22:09:07             86.0   \n",
       "10  2019-06-12 18:04:25  2019-06-12 18:15:57            241.0   \n",
       "11  2019-08-31 13:12:58  2019-08-31 13:34:22            304.0   \n",
       "12  2019-10-17 08:56:41  2019-10-17 09:02:35             61.0   \n",
       "13  2019-02-12 07:11:41  2019-02-12 07:15:22            223.0   \n",
       "14  2019-03-13 11:36:57  2019-03-13 11:45:29            252.0   \n",
       "15  2019-02-01 11:38:20  2019-02-01 11:53:14            139.0   \n",
       "16  2019-07-10 17:16:46  2019-07-10 17:23:22             79.0   \n",
       "17  2019-07-28 13:49:45  2019-07-28 14:17:33              NaN   \n",
       "18  2019-12-23 09:06:10  2019-12-23 09:10:45            323.0   \n",
       "19  2019-01-10 09:55:28  2019-01-10 09:59:27            223.0   \n",
       "\n",
       "   start_station_lat start_station_lon end_station_id end_station_lat  \\\n",
       "0          37.780526       -122.390288          453.0       37.777934   \n",
       "1          37.783521       -122.431158           74.0       37.776435   \n",
       "2          37.795393        -122.40477          399.0       37.802636   \n",
       "3          37.763242       -122.430675           72.0       37.772406   \n",
       "4          37.775235       -122.397437           50.0       37.780526   \n",
       "5            37.7671       -122.410662           74.0       37.776435   \n",
       "6          37.776639       -122.395526            8.0       37.799953   \n",
       "7          37.781074       -122.411738           55.0       37.777053   \n",
       "8          37.798572       -122.400869            6.0        37.80477   \n",
       "9          37.769305       -122.426826           39.0       37.778999   \n",
       "10         37.852477       -122.270213          271.0       37.855783   \n",
       "11         37.348759       -121.894798          282.0       37.332426   \n",
       "12         37.776513       -122.411306           90.0       37.771058   \n",
       "13         37.764765       -122.420091          100.0         37.7671   \n",
       "14         37.865847       -122.267443          241.0       37.852477   \n",
       "15         37.751017       -122.411901          104.0       37.767045   \n",
       "16         37.773492       -122.403672           44.0       37.781074   \n",
       "17         37.806791       -122.419491            NaN       37.798469   \n",
       "18         37.798014        -122.40595           14.0       37.795001   \n",
       "19         37.764765       -122.420091          112.0       37.763847   \n",
       "\n",
       "   end_station_lon   bike_id  \n",
       "0      -122.396973   12424.0  \n",
       "1      -122.426244    1718.0  \n",
       "2      -122.436289     608.0  \n",
       "3       -122.43565  551642.0  \n",
       "4      -122.390288    1103.0  \n",
       "5      -122.426244    1473.0  \n",
       "6      -122.398525    4984.0  \n",
       "7      -122.429558    2666.0  \n",
       "8      -122.403234    1961.0  \n",
       "9      -122.436861    9717.0  \n",
       "10     -122.283127     840.0  \n",
       "11     -121.890349    3412.0  \n",
       "12     -122.402717   12353.0  \n",
       "13     -122.410662    5185.0  \n",
       "14     -122.270213    5172.0  \n",
       "15     -122.390833    4813.0  \n",
       "16     -122.411738    1312.0  \n",
       "17     -122.401155  928582.0  \n",
       "18      -122.39997   12895.0  \n",
       "19     -122.413004     845.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv file and set the index column by 0\n",
    "df = pd.read_csv(\"baywheels_2019\", encoding=\"ISO-8859-1\", index_col=0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2507003 entries, 0 to 2507002\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   start_time         object\n",
      " 1   end_time           object\n",
      " 2   start_station_id   object\n",
      " 3   start_station_lat  object\n",
      " 4   start_station_lon  object\n",
      " 5   end_station_id     object\n",
      " 6   end_station_lat    object\n",
      " 7   end_station_lon    object\n",
      " 8   bike_id            object\n",
      "dtypes: object(9)\n",
      "memory usage: 191.3+ MB\n",
      "None\n",
      "       start_time end_time  start_station_id  start_station_lat  \\\n",
      "count     2507003  2507003         2426269.0       2.507003e+06   \n",
      "unique    2304544  2303004             867.0       7.712800e+04   \n",
      "top       Failure  Failure              58.0       3.777662e+01   \n",
      "freq           10       10           34467.0       3.446700e+04   \n",
      "\n",
      "        start_station_lon  end_station_id  end_station_lat  end_station_lon  \\\n",
      "count        2.507003e+06       2424101.0     2.507003e+06     2.507003e+06   \n",
      "unique       7.795100e+04           869.0     7.936400e+04     8.005900e+04   \n",
      "top         -1.224174e+02            67.0     3.777664e+01    -1.223955e+02   \n",
      "freq         3.446700e+04         39879.0     3.987900e+04     3.987900e+04   \n",
      "\n",
      "          bike_id  \n",
      "count   2507003.0  \n",
      "unique    22024.0  \n",
      "top        3135.0  \n",
      "freq        692.0  \n"
     ]
    }
   ],
   "source": [
    "# take a look at the data types and general information\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data types are not specified which makes it hard to work with. After inspecting the dataset, there are rows containing \"Failure\" so we want to remove all of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_lat</th>\n",
       "      <th>start_station_lon</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_lat</th>\n",
       "      <th>end_station_lon</th>\n",
       "      <th>bike_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381556</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485428</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621119</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713198</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150787</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558857</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676023</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697405</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999499</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249494</th>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "      <td>Failure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_time end_time start_station_id start_station_lat  \\\n",
       "381556     Failure  Failure          Failure           Failure   \n",
       "485428     Failure  Failure          Failure           Failure   \n",
       "621119     Failure  Failure          Failure           Failure   \n",
       "713198     Failure  Failure          Failure           Failure   \n",
       "1150787    Failure  Failure          Failure           Failure   \n",
       "1558857    Failure  Failure          Failure           Failure   \n",
       "1676023    Failure  Failure          Failure           Failure   \n",
       "1697405    Failure  Failure          Failure           Failure   \n",
       "1999499    Failure  Failure          Failure           Failure   \n",
       "2249494    Failure  Failure          Failure           Failure   \n",
       "\n",
       "        start_station_lon end_station_id end_station_lat end_station_lon  \\\n",
       "381556            Failure        Failure         Failure         Failure   \n",
       "485428            Failure        Failure         Failure         Failure   \n",
       "621119            Failure        Failure         Failure         Failure   \n",
       "713198            Failure        Failure         Failure         Failure   \n",
       "1150787           Failure        Failure         Failure         Failure   \n",
       "1558857           Failure        Failure         Failure         Failure   \n",
       "1676023           Failure        Failure         Failure         Failure   \n",
       "1697405           Failure        Failure         Failure         Failure   \n",
       "1999499           Failure        Failure         Failure         Failure   \n",
       "2249494           Failure        Failure         Failure         Failure   \n",
       "\n",
       "         bike_id  \n",
       "381556   Failure  \n",
       "485428   Failure  \n",
       "621119   Failure  \n",
       "713198   Failure  \n",
       "1150787  Failure  \n",
       "1558857  Failure  \n",
       "1676023  Failure  \n",
       "1697405  Failure  \n",
       "1999499  Failure  \n",
       "2249494  Failure  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new data frame that containts all failure rows from dft\n",
    "rent_failure = df[\"start_time\"].str.contains(\"Failure\")\n",
    "data_failure = df[rent_failure]\n",
    "data_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that match failure rows\n",
    "df = df.drop(data_failure.index, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transform Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert every feature to the correct data types in order to to make calculations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2506993 entries, 0 to 2507002\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   start_time         datetime64[ns]\n",
      " 1   end_time           datetime64[ns]\n",
      " 2   start_station_id   Int64         \n",
      " 3   start_station_lat  float64       \n",
      " 4   start_station_lon  float64       \n",
      " 5   end_station_id     Int64         \n",
      " 6   end_station_lat    float64       \n",
      " 7   end_station_lon    float64       \n",
      " 8   bike_id            Int64         \n",
      "dtypes: Int64(3), datetime64[ns](2), float64(4)\n",
      "memory usage: 198.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df[\"bike_id\"]= pd.to_numeric(df[\"bike_id\"], errors='coerce')\n",
    "df[\"bike_id\"]= df[\"bike_id\"].astype('Int64')\n",
    "df[\"start_station_lat\"]= pd.to_numeric(df[\"start_station_lat\"], errors='coerce')\n",
    "df[\"start_station_lon\"]=pd.to_numeric(df[\"start_station_lon\"], errors='coerce')\n",
    "df['start_station_lat'] = df['start_station_lat'].round(6)\n",
    "df['start_station_lon'] = df['start_station_lon'].round(6)\n",
    "df[\"end_station_lat\"]=pd.to_numeric(df[\"end_station_lat\"], errors='coerce')\n",
    "df[\"end_station_lon\"]=pd.to_numeric(df[\"end_station_lon\"], errors='coerce')\n",
    "df[\"start_station_id\"] =pd.to_numeric(df[\"start_station_id\"], errors='coerce')\n",
    "df[\"start_station_id\"]= df[\"start_station_id\"].astype(\"Int64\")\n",
    "df[\"end_station_id\"] =pd.to_numeric(df[\"end_station_id\"], errors='coerce')\n",
    "df[\"end_station_id\"]= df[\"end_station_id\"].astype(\"Int64\")\n",
    "\n",
    "df[\"start_time\"]= pd.to_datetime(df[\"start_time\"],format ='%Y-%m-%d %H:%M:%S')\n",
    "df[\"end_time\"]= pd.to_datetime(df[\"end_time\"],format ='%Y-%m-%d %H:%M:%S')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_time               0\n",
       "end_time                 0\n",
       "start_station_id     80734\n",
       "start_station_lat        0\n",
       "start_station_lon        0\n",
       "end_station_id       82902\n",
       "end_station_lat          0\n",
       "end_station_lon          0\n",
       "bike_id                  1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After transforming the data we check if there are any non-defined values.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_lat</th>\n",
       "      <th>start_station_lon</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_lat</th>\n",
       "      <th>end_station_lon</th>\n",
       "      <th>bike_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-28 13:49:45</td>\n",
       "      <td>2019-07-28 14:17:33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.806791</td>\n",
       "      <td>-122.419491</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.798469</td>\n",
       "      <td>-122.401155</td>\n",
       "      <td>928582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-12-12 17:49:31</td>\n",
       "      <td>2019-12-12 18:08:43</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.334925</td>\n",
       "      <td>-121.892451</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.336896</td>\n",
       "      <td>-121.876394</td>\n",
       "      <td>211150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-07-22 16:46:26</td>\n",
       "      <td>2019-07-22 17:17:12</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.801673</td>\n",
       "      <td>-122.444816</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.807854</td>\n",
       "      <td>-122.418555</td>\n",
       "      <td>183615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-07-17 08:49:28</td>\n",
       "      <td>2019-07-17 09:07:23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.856264</td>\n",
       "      <td>-122.285781</td>\n",
       "      <td>256</td>\n",
       "      <td>37.875112</td>\n",
       "      <td>-122.260553</td>\n",
       "      <td>392211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-07-24 11:56:17</td>\n",
       "      <td>2019-07-24 12:05:06</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.804854</td>\n",
       "      <td>-122.269595</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.798805</td>\n",
       "      <td>-122.260244</td>\n",
       "      <td>250740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506932</th>\n",
       "      <td>2019-12-02 07:31:20</td>\n",
       "      <td>2019-12-02 08:36:24</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.332835</td>\n",
       "      <td>-121.892882</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.402764</td>\n",
       "      <td>-121.940023</td>\n",
       "      <td>419120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506941</th>\n",
       "      <td>2019-12-04 04:57:36</td>\n",
       "      <td>2019-12-04 05:03:18</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.310447</td>\n",
       "      <td>-121.895164</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.311285</td>\n",
       "      <td>-121.884870</td>\n",
       "      <td>676328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506972</th>\n",
       "      <td>2019-11-28 22:30:18</td>\n",
       "      <td>2019-11-28 22:35:15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.342053</td>\n",
       "      <td>-121.910386</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.342588</td>\n",
       "      <td>-121.911388</td>\n",
       "      <td>211150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506975</th>\n",
       "      <td>2019-07-22 13:18:37</td>\n",
       "      <td>2019-07-22 13:32:23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.803232</td>\n",
       "      <td>-122.400816</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.791067</td>\n",
       "      <td>-122.400340</td>\n",
       "      <td>904759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506980</th>\n",
       "      <td>2019-07-29 22:07:46</td>\n",
       "      <td>2019-07-29 22:18:37</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.340199</td>\n",
       "      <td>-121.904019</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>37.331726</td>\n",
       "      <td>-121.874527</td>\n",
       "      <td>108115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99724 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start_time            end_time  start_station_id  \\\n",
       "17      2019-07-28 13:49:45 2019-07-28 14:17:33              <NA>   \n",
       "33      2019-12-12 17:49:31 2019-12-12 18:08:43              <NA>   \n",
       "35      2019-07-22 16:46:26 2019-07-22 17:17:12              <NA>   \n",
       "54      2019-07-17 08:49:28 2019-07-17 09:07:23              <NA>   \n",
       "64      2019-07-24 11:56:17 2019-07-24 12:05:06              <NA>   \n",
       "...                     ...                 ...               ...   \n",
       "2506932 2019-12-02 07:31:20 2019-12-02 08:36:24              <NA>   \n",
       "2506941 2019-12-04 04:57:36 2019-12-04 05:03:18              <NA>   \n",
       "2506972 2019-11-28 22:30:18 2019-11-28 22:35:15              <NA>   \n",
       "2506975 2019-07-22 13:18:37 2019-07-22 13:32:23              <NA>   \n",
       "2506980 2019-07-29 22:07:46 2019-07-29 22:18:37              <NA>   \n",
       "\n",
       "         start_station_lat  start_station_lon  end_station_id  \\\n",
       "17               37.806791        -122.419491            <NA>   \n",
       "33               37.334925        -121.892451            <NA>   \n",
       "35               37.801673        -122.444816            <NA>   \n",
       "54               37.856264        -122.285781             256   \n",
       "64               37.804854        -122.269595            <NA>   \n",
       "...                    ...                ...             ...   \n",
       "2506932          37.332835        -121.892882            <NA>   \n",
       "2506941          37.310447        -121.895164            <NA>   \n",
       "2506972          37.342053        -121.910386            <NA>   \n",
       "2506975          37.803232        -122.400816            <NA>   \n",
       "2506980          37.340199        -121.904019            <NA>   \n",
       "\n",
       "         end_station_lat  end_station_lon  bike_id  \n",
       "17             37.798469      -122.401155   928582  \n",
       "33             37.336896      -121.876394   211150  \n",
       "35             37.807854      -122.418555   183615  \n",
       "54             37.875112      -122.260553   392211  \n",
       "64             37.798805      -122.260244   250740  \n",
       "...                  ...              ...      ...  \n",
       "2506932        37.402764      -121.940023   419120  \n",
       "2506941        37.311285      -121.884870   676328  \n",
       "2506972        37.342588      -121.911388   211150  \n",
       "2506975        37.791067      -122.400340   904759  \n",
       "2506980        37.331726      -121.874527   108115  \n",
       "\n",
       "[99724 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"start_station_id\"].isnull() | df[\"end_station_id\"].isnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handle missing and incorrect values\n",
    "\n",
    "Firstly, we noticed that there are entries which have invalid start or end time (not in 2019). Since the amount of it is less than 5%, we can remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_station_lat</th>\n",
       "      <th>start_station_lon</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_station_lat</th>\n",
       "      <th>end_station_lon</th>\n",
       "      <th>bike_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-28 09:46:47</td>\n",
       "      <td>2019-10-28 09:51:05</td>\n",
       "      <td>50</td>\n",
       "      <td>37.780526</td>\n",
       "      <td>-122.390288</td>\n",
       "      <td>453</td>\n",
       "      <td>37.777934</td>\n",
       "      <td>-122.396973</td>\n",
       "      <td>12424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-10 19:31:02</td>\n",
       "      <td>2019-08-10 19:35:05</td>\n",
       "      <td>285</td>\n",
       "      <td>37.783521</td>\n",
       "      <td>-122.431158</td>\n",
       "      <td>74</td>\n",
       "      <td>37.776435</td>\n",
       "      <td>-122.426244</td>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-05-27 13:18:58</td>\n",
       "      <td>2019-05-27 13:46:37</td>\n",
       "      <td>10</td>\n",
       "      <td>37.795393</td>\n",
       "      <td>-122.404770</td>\n",
       "      <td>399</td>\n",
       "      <td>37.802636</td>\n",
       "      <td>-122.436289</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-24 22:47:58</td>\n",
       "      <td>2019-07-24 22:52:48</td>\n",
       "      <td>106</td>\n",
       "      <td>37.763242</td>\n",
       "      <td>-122.430675</td>\n",
       "      <td>72</td>\n",
       "      <td>37.772406</td>\n",
       "      <td>-122.435650</td>\n",
       "      <td>551642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-04-28 17:26:22</td>\n",
       "      <td>2019-04-28 17:31:54</td>\n",
       "      <td>80</td>\n",
       "      <td>37.775235</td>\n",
       "      <td>-122.397437</td>\n",
       "      <td>50</td>\n",
       "      <td>37.780526</td>\n",
       "      <td>-122.390288</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506998</th>\n",
       "      <td>2019-04-12 19:11:48</td>\n",
       "      <td>2019-04-12 19:17:34</td>\n",
       "      <td>109</td>\n",
       "      <td>37.763316</td>\n",
       "      <td>-122.421904</td>\n",
       "      <td>381</td>\n",
       "      <td>37.758238</td>\n",
       "      <td>-122.426094</td>\n",
       "      <td>6118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506999</th>\n",
       "      <td>2019-07-16 19:02:32</td>\n",
       "      <td>2019-07-16 19:06:54</td>\n",
       "      <td>58</td>\n",
       "      <td>37.776619</td>\n",
       "      <td>-122.417385</td>\n",
       "      <td>5</td>\n",
       "      <td>37.783899</td>\n",
       "      <td>-122.408445</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507000</th>\n",
       "      <td>2019-05-29 16:03:26</td>\n",
       "      <td>2019-05-29 16:09:25</td>\n",
       "      <td>23</td>\n",
       "      <td>37.791464</td>\n",
       "      <td>-122.391034</td>\n",
       "      <td>15</td>\n",
       "      <td>37.795392</td>\n",
       "      <td>-122.394203</td>\n",
       "      <td>1742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507001</th>\n",
       "      <td>2019-08-19 08:32:17</td>\n",
       "      <td>2019-08-19 08:41:26</td>\n",
       "      <td>23</td>\n",
       "      <td>37.791464</td>\n",
       "      <td>-122.391034</td>\n",
       "      <td>364</td>\n",
       "      <td>37.772000</td>\n",
       "      <td>-122.389970</td>\n",
       "      <td>10107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2507002</th>\n",
       "      <td>2019-04-02 17:00:36</td>\n",
       "      <td>2019-04-02 17:06:28</td>\n",
       "      <td>64</td>\n",
       "      <td>37.776754</td>\n",
       "      <td>-122.399018</td>\n",
       "      <td>3</td>\n",
       "      <td>37.786375</td>\n",
       "      <td>-122.404904</td>\n",
       "      <td>5359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2506983 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 start_time            end_time  start_station_id  \\\n",
       "0       2019-10-28 09:46:47 2019-10-28 09:51:05                50   \n",
       "1       2019-08-10 19:31:02 2019-08-10 19:35:05               285   \n",
       "2       2019-05-27 13:18:58 2019-05-27 13:46:37                10   \n",
       "3       2019-07-24 22:47:58 2019-07-24 22:52:48               106   \n",
       "4       2019-04-28 17:26:22 2019-04-28 17:31:54                80   \n",
       "...                     ...                 ...               ...   \n",
       "2506998 2019-04-12 19:11:48 2019-04-12 19:17:34               109   \n",
       "2506999 2019-07-16 19:02:32 2019-07-16 19:06:54                58   \n",
       "2507000 2019-05-29 16:03:26 2019-05-29 16:09:25                23   \n",
       "2507001 2019-08-19 08:32:17 2019-08-19 08:41:26                23   \n",
       "2507002 2019-04-02 17:00:36 2019-04-02 17:06:28                64   \n",
       "\n",
       "         start_station_lat  start_station_lon  end_station_id  \\\n",
       "0                37.780526        -122.390288             453   \n",
       "1                37.783521        -122.431158              74   \n",
       "2                37.795393        -122.404770             399   \n",
       "3                37.763242        -122.430675              72   \n",
       "4                37.775235        -122.397437              50   \n",
       "...                    ...                ...             ...   \n",
       "2506998          37.763316        -122.421904             381   \n",
       "2506999          37.776619        -122.417385               5   \n",
       "2507000          37.791464        -122.391034              15   \n",
       "2507001          37.791464        -122.391034             364   \n",
       "2507002          37.776754        -122.399018               3   \n",
       "\n",
       "         end_station_lat  end_station_lon  bike_id  \n",
       "0              37.777934      -122.396973    12424  \n",
       "1              37.776435      -122.426244     1718  \n",
       "2              37.802636      -122.436289      608  \n",
       "3              37.772406      -122.435650   551642  \n",
       "4              37.780526      -122.390288     1103  \n",
       "...                  ...              ...      ...  \n",
       "2506998        37.758238      -122.426094     6118  \n",
       "2506999        37.783899      -122.408445     1479  \n",
       "2507000        37.795392      -122.394203     1742  \n",
       "2507001        37.772000      -122.389970    10107  \n",
       "2507002        37.786375      -122.404904     5359  \n",
       "\n",
       "[2506983 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop some rows with start_time in 2013\n",
    "df.drop(df[(df['start_time'].dt.year < 2018) | (df['start_time'].dt.year > 2020)].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, there are missing values in <b>start_station_id</b> and <b>end_station_id</b> column. We tried different approaches to handle these values:\n",
    "- Using <b>k-means clustering algorithm</b> to assign an ID to the given longtitudes and latitudes.\n",
    "\n",
    "- <b>Dropping</b> all rows with missing values.\n",
    "\n",
    "The cost of performing the first method was higher than the latter and the amount of missing values take up less than 5%, so we decided to opt for the second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['start_station_id'].isnull() | df['end_station_id'].isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 12, figsize = (20, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something can be interpreted from the above graph:\n",
    "the stations with the station_id under 150 are more occupied than the rest, maybe they are located within city center?\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to calculate idle time\n",
    "2 approach: idle time group by bike_id, and idle time group by station_id\n",
    "\n",
    "the first one is easier to implement \n",
    "\n",
    "Let's go with the first approach first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations =df.loc[:,['start_time', 'start_station_id', 'bike_id']]\n",
    "start_stations[\"rented\"] = 1\n",
    "start_stations.rename(columns = {\"start_time\": \"timestamp\", 'start_station_id': \"station_id\"}, inplace=True)\n",
    "start_stations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try the second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_stations =df.loc[:,['end_time', 'end_station_id', 'bike_id']]\n",
    "end_stations[\"rented\"] = 0\n",
    "end_stations.rename(columns={\"end_time\": \"timestamp\", 'end_station_id': \"station_id\"}, inplace=True)\n",
    "end_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([start_stations, end_stations], axis = 0)\n",
    "df_merged = df_merged.sort_values(by = [\"station_id\", \"timestamp\"])\n",
    "df_merged['idle_time'] = pd.Timedelta(0)\n",
    "df_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that calculates idle time with the help of a nested loop inside the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def idle_cal(df):\n",
    "    \n",
    "    df = df.groupby('station_id')\n",
    "    results = []  # List to store the modified groups\n",
    "    for group_name, group_data in df:\n",
    "        group_data.sort_values(by = 'timestamp', inplace = True)\n",
    "        group_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        group_data['prev_row'] = group_data.groupby(\"station_id\")['timestamp'].shift(1)\n",
    "        for i, row in group_data.iterrows():\n",
    "            if i != 0:\n",
    "                if row['rented'] == 1:\n",
    "                    idle_time = pd.Timedelta(0)\n",
    "                    #print('idle at i ', i , ':', idle_time)\n",
    "                    j = i - 1 \n",
    "                    while j>=1 and group_data.at[j,'rented'] == 0:\n",
    "                        idle_time = group_data.at[i,'timestamp'] -  group_data.at[j,'timestamp']\n",
    "                        group_data.at[j,'idle_time'] = idle_time\n",
    "                        #print('idle at j ', j , ':',  idle_time)\n",
    "                        j -= 1\n",
    "                    \n",
    "        results.append(group_data)\n",
    "\n",
    "    modified_df = (pd.concat(results, ignore_index=True))\n",
    "    df = pd.DataFrame(modified_df)\n",
    "    return df\n",
    "    \n",
    "                    \n",
    "        \n",
    "\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = idle_cal(df_merged)\n",
    "df_merged.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('idle_time_calculated')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull =df_merged[df_merged['idle_time']!=pd.Timedelta(0)]\n",
    "print(notnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time = pd.read_csv(\"idle_time_calculated\")\n",
    "idle_time_per_trip = df_w_idle_time[df_w_idle_time['rented'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4814518 entries, 0 to 4814517\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Dtype          \n",
      "---  ------           -----          \n",
      " 0   Unnamed: 0       int64          \n",
      " 1   timestamp        datetime64[ns] \n",
      " 2   station_id       int64          \n",
      " 3   bike_id          int64          \n",
      " 4   rented           int64          \n",
      " 5   idle_time        object         \n",
      " 6   sum_idle_time    timedelta64[ns]\n",
      " 7   idle_mode_count  int64          \n",
      " 8   month            int64          \n",
      "dtypes: datetime64[ns](1), int64(6), object(1), timedelta64[ns](1)\n",
      "memory usage: 330.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_w_idle_time.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time['timestamp']= pd.to_datetime(df_w_idle_time['timestamp'],format ='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/2xng7w014d1f2mbbxqsxbwg40000gn/T/ipykernel_7668/96042065.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  idle_time_per_trip['end_time'] = idle_time_per_trip['timestamp']\n",
      "/var/folders/nf/2xng7w014d1f2mbbxqsxbwg40000gn/T/ipykernel_7668/96042065.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  idle_time_per_trip['end_time'] = pd.to_datetime(idle_time_per_trip['end_time'], format = '%Y-%m-%d %H:%M:%S')\n"
     ]
    }
   ],
   "source": [
    "idle_time_per_trip['end_time'] = idle_time_per_trip['timestamp']\n",
    "idle_time_per_trip['end_time'] = pd.to_datetime(idle_time_per_trip['end_time'], format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_trip = pd.merge(df, idle_time_per_trip, on = ['end_time', 'bike_id'])\n",
    "df_trip = df_trip.sort_values(by = 'end_time')\n",
    "#[df_trip['end_time'] < '2020-01-01']\n",
    "#df_trip.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip = df_trip.drop(['Unnamed: 0','timestamp','station_id','rented'], axis=1)\n",
    "\n",
    "#df_trip.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_w_idle_time['sum_idle_time']= pd.Timedelta(0)\n",
    "df_w_idle_time['idle_mode_count']= 0\n",
    "df_w_idle_time['month']= df_w_idle_time['timestamp'].dt.month\n",
    "#df_w_idle_time.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_idle_cal(df):\n",
    "    \n",
    "    df = df.groupby('station_id')\n",
    "    results = {}  # dict to store the modified groups\n",
    "    \n",
    "    for group_name, group_data in df:\n",
    "        group_data.sort_values(by = 'timestamp', inplace = True)\n",
    "        group_data.reset_index(drop=True, inplace=True)\n",
    "        sum_idle_time= pd.Timedelta(0)\n",
    "        idle_mode_count = 0\n",
    "    \n",
    "        for i, row in group_data.iterrows():\n",
    "            if i != 0:\n",
    "                j = i - 1\n",
    "                \n",
    "                if row['rented']==0 and group_data.at[j,'rented'] == 1:\n",
    "                    sum_idle_time += group_data.at[j,'sum_idle_time']+ group_data.at[i,'idle_time']\n",
    "                    idle_mode_count +=1\n",
    "                else:\n",
    "                    sum_idle_time += group_data.at[j,'sum_idle_time']\n",
    "                    \n",
    "            else:\n",
    "                sum_idle_time+= group_data.at[i,'idle_time']\n",
    "                \n",
    "                idle_mode_count+= 1\n",
    "    \n",
    "        #print(group_name,'sum idle at i ', len(group_data.index)-1, ':', sum_idle_time, 'idle count :',idle_mode_count)\n",
    "        #idle_sum = group_data.at[len(group_data.index)-1,'sum_idle_time'] \n",
    "        results[str(group_name)] = [sum_idle_time, idle_mode_count]\n",
    "            \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "    #     results.append(group_data)\n",
    "\n",
    "    # modified_df = (pd.concat(results, ignore_index=True))\n",
    "    # df = pd.DataFrame(modified_df)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 383684 entries, 0 to 4715623\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count   Dtype          \n",
      "---  ------           --------------   -----          \n",
      " 0   Unnamed: 0       383684 non-null  int64          \n",
      " 1   timestamp        383684 non-null  datetime64[ns] \n",
      " 2   station_id       383684 non-null  int64          \n",
      " 3   bike_id          383684 non-null  int64          \n",
      " 4   rented           383684 non-null  int64          \n",
      " 5   idle_time        383684 non-null  timedelta64[ns]\n",
      " 6   sum_idle_time    383684 non-null  timedelta64[ns]\n",
      " 7   idle_mode_count  383684 non-null  int64          \n",
      " 8   month            383684 non-null  int64          \n",
      "dtypes: datetime64[ns](1), int64(6), timedelta64[ns](2)\n",
      "memory usage: 29.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_jan = df_w_idle_time[df_w_idle_time['month'] == 1]\n",
    "df_jan.head(10)\n",
    "df_jan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "january = sum_idle_cal(df_jan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>idle_sum</th>\n",
       "      <th>idle_count</th>\n",
       "      <th>idle_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>13 days 01:04:12</td>\n",
       "      <td>1472</td>\n",
       "      <td>0 days 00:12:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>10 days 20:36:26</td>\n",
       "      <td>321</td>\n",
       "      <td>0 days 00:48:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>12 days 04:06:56</td>\n",
       "      <td>1212</td>\n",
       "      <td>0 days 00:14:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>18 days 03:41:10</td>\n",
       "      <td>1095</td>\n",
       "      <td>0 days 00:23:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>11 days 22:48:27</td>\n",
       "      <td>305</td>\n",
       "      <td>0 days 00:56:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>12 days 08:58:38</td>\n",
       "      <td>289</td>\n",
       "      <td>0 days 01:01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>12 days 06:35:56</td>\n",
       "      <td>439</td>\n",
       "      <td>0 days 00:40:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>16 days 21:07:15</td>\n",
       "      <td>403</td>\n",
       "      <td>0 days 01:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>13 days 23:48:53</td>\n",
       "      <td>493</td>\n",
       "      <td>0 days 00:40:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id         idle_sum  idle_count        idle_avg\n",
       "0          3 13 days 01:04:12        1472 0 days 00:12:46\n",
       "1          4 10 days 20:36:26         321 0 days 00:48:43\n",
       "2          5 12 days 04:06:56        1212 0 days 00:14:28\n",
       "3          6 18 days 03:41:10        1095 0 days 00:23:52\n",
       "4          7 11 days 22:48:27         305 0 days 00:56:25\n",
       "5          8 12 days 08:58:38         289 0 days 01:01:39\n",
       "6          9 12 days 06:35:56         439 0 days 00:40:16\n",
       "7         10 16 days 21:07:15         403 0 days 01:00:19\n",
       "8         11 13 days 23:48:53         493 0 days 00:40:52\n",
       "9         12  0 days 00:00:00           1 0 days 00:00:00"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jan = pd.DataFrame(columns= [\"station_id\", \"idle_sum\", \"idle_count\"])\n",
    "df_jan[\"station_id\"] = january.keys()\n",
    "modified_values = list(zip(*january.values()))\n",
    "df_jan[\"idle_sum\"] = modified_values[0]\n",
    "df_jan[\"idle_count\"] = modified_values[1]\n",
    "df_jan[\"idle_avg\"] = (df_jan[\"idle_sum\"]/ df_jan[\"idle_count\"]).dt.round('1s')\n",
    "# df_jan[\"idle_avg\"] = df_jan[\"idle_avg\"].dt.round('1s')\n",
    "df_jan.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_idle_sum(month):\n",
    "    df = df_w_idle_time[df_w_idle_time['month'] == month]\n",
    "    idle_in_month = sum_idle_cal(df)\n",
    "    df = pd.DataFrame(columns= [\"station_id\", \"idle_sum\", \"idle_count\"])\n",
    "    df[\"station_id\"] = idle_in_month.keys()\n",
    "    modified_values = list(zip(*idle_in_month.values()))\n",
    "    df[\"idle_sum\"] = modified_values[0]\n",
    "    df[\"idle_count\"] = modified_values[1]\n",
    "    df[\"idle_avg\"] = (df[\"idle_sum\"]/ df[\"idle_count\"]).dt.round('1s')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    station_id         idle_sum  idle_count\n",
      "0            3 13 days 19:03:30        1216\n",
      "1            4 12 days 07:17:19         272\n",
      "2            5 14 days 12:31:03        1263\n",
      "3            6 15 days 15:49:05        1127\n",
      "4            7 11 days 11:43:50         279\n",
      "..         ...              ...         ...\n",
      "362        423  6 days 01:51:32           7\n",
      "363        424 11 days 20:15:21          63\n",
      "364        425  5 days 22:52:21           8\n",
      "365        426  6 days 00:39:33           9\n",
      "366        427  3 days 07:46:50           3\n",
      "\n",
      "[367 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(monthly_idle_sum(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3b: Working with Weather Data\n",
    "\n",
    "First approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the weather data\n",
    "wd = pd.read_csv(\"SanFrancisco\", encoding=\"ISO-8859-1\", index_col=0)\n",
    "# show first 20 rows\n",
    "wd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the data types and general information\n",
    "print(wd.info())\n",
    "print(wd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to datetime\n",
    "wd['timestamp'] = pd.to_datetime(wd['timestamp'],format ='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# extract the year from timestamp\n",
    "wd['year'] = wd['timestamp'].dt.year\n",
    "\n",
    "# count how many entries are for what year\n",
    "value_counts = wd['year'].value_counts()\n",
    "\n",
    "# show how many entries has every year, because only 2019 is important\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wd.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the data for the year 2019 is important, so we drop all the other entries.\n",
    "wd = wd[wd['timestamp'].dt.year == 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first 20 entries to look is it was successfull\n",
    "wd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after transforming the data we check if there are any non-defined values.\n",
    "wd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with missing values\n",
    "weather_2019 = wd.dropna(axis = 0)\n",
    "print(weather_2019.info())\n",
    "print(weather_2019.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the temperature in Sanfrancisco in 2019\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(weather_2019[\"timestamp\"],weather_2019[\"temperature\"])\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Grad\")\n",
    "ax.set_title(\"Temperature in Sanfrancisco in 2019\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find out how would the weather affect the bike rent business. With the help of idle_time could we analyze under what kinf of weather (e.g Temperature, Windspeed) where should we put our bikes, so that they can be rented as frequently as possible. We assume that normally when the temparature is high, people would go out like beach, and when it's cold, people would spend time in city center like shopping mall. Then we can separate the weather data in seasons to have a better look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create month feature\n",
    "weather_2019[\"Month\"] = weather_2019[\"timestamp\"].apply(lambda dt: dt.month)\n",
    "weather_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create four seasons\n",
    "spring_month=[3,4,5]\n",
    "spring_2019 = weather_2019[weather_2019[\"Month\"].isin(spring_month)==True]\n",
    "\n",
    "summer_month=[6,7,8]\n",
    "summer_2019 = weather_2019[weather_2019[\"Month\"].isin(summer_month)==True]\n",
    "\n",
    "autumn_month=[9,10,11]\n",
    "autumn_2019 = weather_2019[weather_2019[\"Month\"].isin(autumn_month)==True]\n",
    "\n",
    "winter_month=[12,1,2]\n",
    "winter_2019 = weather_2019[weather_2019[\"Month\"].isin(winter_month)==True]\n",
    "\n",
    "summer_2019.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
