{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ha: Work done so far: change all data types, drop some corrupted rows with at start_time and end_time\n",
    "Delete all rows with null value.\n",
    "Calculating idle time (station-level and trip-level)\n",
    "\n",
    "Import weather data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all relevant libraries\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "register_matplotlib_converters()\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "\n",
    "# also import these \"new\" libraries\n",
    "# Note: you may have to download an add them to your environment (using e.g. 'conda install -c conda-forge folium')\n",
    "import folium\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "from datetime import datetime  # for working with times objects\n",
    "from datetime import timedelta  # for working with times objects\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file and set the index column by 0\n",
    "df = pd.read_csv(\"baywheels_2019\", encoding=\"ISO-8859-1\", index_col=0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the data types and general information\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data types are not specified which makes it hard to work with. After inspecting the dataset, there are rows containing \"Failure\" so we want to remove all of these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data frame that containts all failure rows from dft\n",
    "rent_failure = df[\"start_time\"].str.contains(\"Failure\")\n",
    "data_failure = df[rent_failure]\n",
    "data_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all rows that match failure rows\n",
    "df = df.drop(data_failure.index, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transform Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to convert every feature to the correct data types in order to to make calculations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bike_id\"]= pd.to_numeric(df[\"bike_id\"], errors='coerce')\n",
    "df[\"bike_id\"]= df[\"bike_id\"].astype('Int64')\n",
    "df[\"start_station_lat\"]= pd.to_numeric(df[\"start_station_lat\"], errors='coerce')\n",
    "df[\"start_station_lon\"]=pd.to_numeric(df[\"start_station_lon\"], errors='coerce')\n",
    "df['start_station_lat'] = df['start_station_lat'].round(6)\n",
    "df['start_station_lon'] = df['start_station_lon'].round(6)\n",
    "df[\"end_station_lat\"]=pd.to_numeric(df[\"end_station_lat\"], errors='coerce')\n",
    "df[\"end_station_lon\"]=pd.to_numeric(df[\"end_station_lon\"], errors='coerce')\n",
    "df[\"start_station_id\"] =pd.to_numeric(df[\"start_station_id\"], errors='coerce')\n",
    "df[\"start_station_id\"]= df[\"start_station_id\"].astype(\"Int64\")\n",
    "df[\"end_station_id\"] =pd.to_numeric(df[\"end_station_id\"], errors='coerce')\n",
    "df[\"end_station_id\"]= df[\"end_station_id\"].astype(\"Int64\")\n",
    "\n",
    "df[\"start_time\"]= pd.to_datetime(df[\"start_time\"],format ='%Y-%m-%d %H:%M:%S')\n",
    "df[\"end_time\"]= pd.to_datetime(df[\"end_time\"],format ='%Y-%m-%d %H:%M:%S')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After transforming the data we check if there are any non-defined values.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"start_station_id\"].isnull() | df[\"end_station_id\"].isnull()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handle missing and incorrect values\n",
    "\n",
    "Firstly, we noticed that there are entries which have invalid start or end time (not in 2019). Since the amount of it is less than 5%, we can remove these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some rows with start_time in 2013\n",
    "df.drop(df[(df['start_time'].dt.year < 2018) | (df['start_time'].dt.year > 2020)].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, there are missing values in <b>start_station_id</b> and <b>end_station_id</b> column. We tried different approaches to handle these values:\n",
    "- Using <b>k-means clustering algorithm</b> to assign an ID to the given longtitudes and latitudes.\n",
    "\n",
    "- <b>Dropping</b> all rows with missing values.\n",
    "\n",
    "The cost of performing the first method was higher than the latter and the amount of missing values take up less than 5%, so we decided to opt for the second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['start_station_id'].isnull() | df['end_station_id'].isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(bins = 12, figsize = (20, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something can be interpreted from the above graph:\n",
    "the stations with the station_id under 150 are more occupied than the rest, maybe they are located within city center?\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to calculate idle time\n",
    "2 approach: idle time group by bike_id, and idle time group by station_id\n",
    "\n",
    "the first one is easier to implement \n",
    "\n",
    "Let's go with the first approach first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_stations =df.loc[:,['start_time', 'start_station_id', 'bike_id']]\n",
    "start_stations[\"rented\"] = 1\n",
    "start_stations.rename(columns = {\"start_time\": \"timestamp\", 'start_station_id': \"station_id\"}, inplace=True)\n",
    "start_stations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try the second approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_stations =df.loc[:,['end_time', 'end_station_id', 'bike_id']]\n",
    "end_stations[\"rented\"] = 0\n",
    "end_stations.rename(columns={\"end_time\": \"timestamp\", 'end_station_id': \"station_id\"}, inplace=True)\n",
    "end_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([start_stations, end_stations], axis = 0)\n",
    "df_merged = df_merged.sort_values(by = [\"station_id\", \"timestamp\"])\n",
    "df_merged['idle_time'] = pd.Timedelta(0)\n",
    "df_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that calculates idle time with the help of a nested loop inside the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def idle_cal(df):\n",
    "    \n",
    "    df = df.groupby('station_id')\n",
    "    results = []  # List to store the modified groups\n",
    "    for group_name, group_data in df:\n",
    "        group_data.sort_values(by = 'timestamp', inplace = True)\n",
    "        group_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "        group_data['prev_row'] = group_data.groupby(\"station_id\")['timestamp'].shift(1)\n",
    "        for i, row in group_data.iterrows():\n",
    "            if i != 0:\n",
    "                if row['rented'] == 1:\n",
    "                    idle_time = pd.Timedelta(0)\n",
    "                    #print('idle at i ', i , ':', idle_time)\n",
    "                    j = i - 1 \n",
    "                    while j>=1 and group_data.at[j,'rented'] == 0:\n",
    "                        idle_time = group_data.at[i,'timestamp'] -  group_data.at[j,'timestamp']\n",
    "                        group_data.at[j,'idle_time'] = idle_time\n",
    "                        #print('idle at j ', j , ':',  idle_time)\n",
    "                        j -= 1\n",
    "                    \n",
    "        results.append(group_data)\n",
    "\n",
    "    modified_df = (pd.concat(results, ignore_index=True))\n",
    "    df = pd.DataFrame(modified_df)\n",
    "    return df\n",
    "    \n",
    "                    \n",
    "        \n",
    "\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = idle_cal(df_merged)\n",
    "df_merged.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_csv('idle_time_calculated')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notnull =df_merged[df_merged['idle_time']!=pd.Timedelta(0)]\n",
    "print(notnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time = pd.read_csv(\"idle_time_calculated\")\n",
    "idle_time_per_trip = df_w_idle_time[df_w_idle_time['rented'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time['timestamp']= pd.to_datetime(df_w_idle_time['timestamp'],format ='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idle_time_per_trip['end_time'] = idle_time_per_trip['timestamp']\n",
    "idle_time_per_trip['end_time'] = pd.to_datetime(idle_time_per_trip['end_time'], format = '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_trip = pd.merge(df, idle_time_per_trip, on = ['end_time', 'bike_id'])\n",
    "df_trip = df_trip.sort_values(by = 'end_time')\n",
    "#[df_trip['end_time'] < '2020-01-01']\n",
    "df_trip.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip = df_trip.drop(['Unnamed: 0','timestamp','station_id','rented'], axis=1)\n",
    "\n",
    "df_trip.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_w_idle_time['sum_idle_time']= pd.Timedelta(0)\n",
    "df_w_idle_time['idle_mode_count']= 0\n",
    "df_w_idle_time['month']= df_w_idle_time['timestamp'].dt.month\n",
    "df_w_idle_time.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time['tim'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_idle_cal(df,interval ='monthly'):\n",
    "    \n",
    "    df = df.groupby('station_id')\n",
    "    results = []  # List to store the modified groups\n",
    "    \n",
    "    for group_name, group_data in df:\n",
    "        group_data.sort_values(by = 'timestamp', inplace = True)\n",
    "        group_data.reset_index(drop=True, inplace=True)\n",
    "        sum_idle_time= pd.Timedelta(0)\n",
    "        idle_mode_count = 0\n",
    "        \n",
    "        if interval == 'monthly':\n",
    "            group_data['month'] = group_data['timestamp'].dt.to_period('M')\n",
    "        elif interval == 'daily':\n",
    "            group_data['day'] = group_data['timestamp'].dt.to_period('D')\n",
    "    \n",
    "        for i, row in group_data.iterrows():\n",
    "            if i != 0:\n",
    "                j = i - 1\n",
    "                \n",
    "                if row['rented']==0 and group_data.at[j,'rented'] == 1:\n",
    "                    sum_idle_time += group_data.at[j,'sum_idle_time']+ group_data.at[i,'idle_time']\n",
    "                    idle_mode_count +=1\n",
    "                else:\n",
    "                    sum_idle_time += group_data.at[j,'sum_idle_time']\n",
    "                    \n",
    "            else:\n",
    "                sum_idle_time+= group_data.at[i,'idle_time']\n",
    "                \n",
    "                idle_mode_count+= 1\n",
    "            print(group_name,'sum idle at i ', i , ':', sum_idle_time, 'idle count :',idle_mode_count)\n",
    "            \n",
    "            \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                     \n",
    "                    \n",
    "                    \n",
    "        results.append(group_data)\n",
    "\n",
    "    modified_df = (pd.concat(results, ignore_index=True))\n",
    "    df = pd.DataFrame(modified_df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_w_idle_time= sum_idle_cal(df_w_idle_time,interval='monthly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_idle_time.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3b: Working with Weather Data\n",
    "\n",
    "First approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the weather data\n",
    "wd = pd.read_csv(\"SanFrancisco\", encoding=\"ISO-8859-1\", index_col=0)\n",
    "# show first 20 rows\n",
    "wd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the data types and general information\n",
    "print(wd.info())\n",
    "print(wd.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert timestamp to datetime\n",
    "wd['timestamp'] = pd.to_datetime(wd['timestamp'],format ='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# extract the year from timestamp\n",
    "wd['year'] = wd['timestamp'].dt.year\n",
    "\n",
    "# count how many entries are for what year\n",
    "value_counts = wd['year'].value_counts()\n",
    "\n",
    "# show how many entries has every year, because only 2019 is important\n",
    "print(value_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wd.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the data for the year 2019 is important, so we drop all the other entries.\n",
    "wd = wd[wd['timestamp'].dt.year == 2019]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check first 20 entries to look is it was successfull\n",
    "wd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after transforming the data we check if there are any non-defined values.\n",
    "wd.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with missing values\n",
    "weather_2019 = wd.dropna(axis = 0)\n",
    "print(weather_2019.info())\n",
    "print(weather_2019.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the temperature in Sanfrancisco in 2019\n",
    "fig,ax = plt.subplots(figsize=(10,4))\n",
    "ax.plot(weather_2019[\"timestamp\"],weather_2019[\"temperature\"])\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Grad\")\n",
    "ax.set_title(\"Temperature in Sanfrancisco in 2019\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to find out how would the weather affect the bike rent business. With the help of idle_time could we analyze under what kinf of weather (e.g Temperature, Windspeed) where should we put our bikes, so that they can be rented as frequently as possible. We assume that normally when the temparature is high, people would go out like beach, and when it's cold, people would spend time in city center like shopping mall. Then we can separate the weather data in seasons to have a better look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create month feature\n",
    "weather_2019[\"Month\"] = weather_2019[\"timestamp\"].apply(lambda dt: dt.month)\n",
    "weather_2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create four seasons\n",
    "spring_month=[3,4,5]\n",
    "spring_2019 = weather_2019[weather_2019[\"Month\"].isin(spring_month)==True]\n",
    "\n",
    "summer_month=[6,7,8]\n",
    "summer_2019 = weather_2019[weather_2019[\"Month\"].isin(summer_month)==True]\n",
    "\n",
    "autumn_month=[9,10,11]\n",
    "autumn_2019 = weather_2019[weather_2019[\"Month\"].isin(autumn_month)==True]\n",
    "\n",
    "winter_month=[12,1,2]\n",
    "winter_2019 = weather_2019[weather_2019[\"Month\"].isin(winter_month)==True]\n",
    "\n",
    "summer_2019.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
